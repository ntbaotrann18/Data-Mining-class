{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1 Tran Dinh Son\n",
    "#trandinhson3086@gmail.com\n",
    "#Chonnam National University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dense, Dropout\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples :  60000\n",
      "Number of testing samples: 10000\n"
     ]
    }
   ],
   "source": [
    "#the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 28, 28)\n",
    "x_test = x_test.reshape(10000, 28, 28)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print('Number of training samples : ', x_train.shape[0])\n",
    "print('Number of testing samples:', x_test.shape[0])\n",
    "\n",
    "# 10 class from 0 to 9: 0 1 2 3.. 9\n",
    "num_classes = 10\n",
    "#convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           (None, 28, 28)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout1 (Dropout)           (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout2 (Dropout)           (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout3 (Dropout)           (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc4_10ways_softmax (Dense)   (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 932,362\n",
      "Trainable params: 932,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 28x28 MNIST image\n",
    "input_image = Input(shape=(28, 28), name='Input')\n",
    "\n",
    "# matrix ---> vector\n",
    "x = Flatten(name='flatten')(input_image)\n",
    "\n",
    "# FC layers + dropout\n",
    "x = Dense(units=512, activation='relu', name='fc1')(x)\n",
    "x = Dropout(rate=0.2, name='dropout1')(x)\n",
    "\n",
    "x = Dense(units=512, activation='relu', name='fc2')(x)\n",
    "x = Dropout(rate=0.2, name='dropout2')(x)\n",
    "\n",
    "x = Dense(units=512, activation='relu', name='fc3')(x)\n",
    "x = Dropout(rate=0.2, name='dropout3')(x)\n",
    "\n",
    "output_label = Dense(units=num_classes, activation='softmax', name='fc4_10ways_softmax')(x)\n",
    "\n",
    "# define model\n",
    "model = Model(inputs=input_image, outputs=output_label, name='mnist_mlp')\n",
    "\n",
    "# print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 1.3766 - acc: 0.6199 - val_loss: 0.5353 - val_acc: 0.8543\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.5598 - acc: 0.8317 - val_loss: 0.3612 - val_acc: 0.8970\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.4322 - acc: 0.8710 - val_loss: 0.3031 - val_acc: 0.9112\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.3750 - acc: 0.8897 - val_loss: 0.2702 - val_acc: 0.9217\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.3363 - acc: 0.9021 - val_loss: 0.2461 - val_acc: 0.9273\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.3076 - acc: 0.9081 - val_loss: 0.2296 - val_acc: 0.9326\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.2851 - acc: 0.9161 - val_loss: 0.2125 - val_acc: 0.9366\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.2671 - acc: 0.9204 - val_loss: 0.1995 - val_acc: 0.9404\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.2474 - acc: 0.9272 - val_loss: 0.1872 - val_acc: 0.9443\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.2344 - acc: 0.9307 - val_loss: 0.1771 - val_acc: 0.9481\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.2217 - acc: 0.9342 - val_loss: 0.1686 - val_acc: 0.9505\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.2076 - acc: 0.9385 - val_loss: 0.1591 - val_acc: 0.9527\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.1987 - acc: 0.9411 - val_loss: 0.1530 - val_acc: 0.9546\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.1913 - acc: 0.9438 - val_loss: 0.1460 - val_acc: 0.9560\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.1801 - acc: 0.9460 - val_loss: 0.1409 - val_acc: 0.9576\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.1735 - acc: 0.9487 - val_loss: 0.1350 - val_acc: 0.9589\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.1668 - acc: 0.9505 - val_loss: 0.1299 - val_acc: 0.9601\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.1602 - acc: 0.9524 - val_loss: 0.1257 - val_acc: 0.9613\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.1545 - acc: 0.9535 - val_loss: 0.1223 - val_acc: 0.9623\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.1485 - acc: 0.9555 - val_loss: 0.1188 - val_acc: 0.9628\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.1436 - acc: 0.9574 - val_loss: 0.1162 - val_acc: 0.9636\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.1397 - acc: 0.9589 - val_loss: 0.1127 - val_acc: 0.9655\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.1360 - acc: 0.9595 - val_loss: 0.1097 - val_acc: 0.9665\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.1307 - acc: 0.9609 - val_loss: 0.1070 - val_acc: 0.9669\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.1264 - acc: 0.9618 - val_loss: 0.1044 - val_acc: 0.9680\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.1247 - acc: 0.9628 - val_loss: 0.1020 - val_acc: 0.9686\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.1215 - acc: 0.9635 - val_loss: 0.0999 - val_acc: 0.9699\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.1155 - acc: 0.9652 - val_loss: 0.0980 - val_acc: 0.9702\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.1124 - acc: 0.9662 - val_loss: 0.0974 - val_acc: 0.9693\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.1115 - acc: 0.9665 - val_loss: 0.0947 - val_acc: 0.9704\n",
      "> training time is 4.4718 minutes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# declare learning rate, loss function, and model metric\n",
    "loss = 'categorical_crossentropy'\n",
    "lr = 0.01\n",
    "model.compile(loss=loss, optimizer=SGD(lr=lr), metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "batch_size = 128\n",
    "epochs = 30\n",
    "\n",
    "starting_time = time.time()\n",
    "history = model.fit(x_train, y_train,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs)\n",
    "print('> training time is %.4f minutes' % ((time.time() - starting_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 102us/step\n",
      "Test loss: 0.09469581072451547\n",
      "Test accuracy: 0.9704\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAFLxJREFUeJzt3X+wXGV9x/H3hwQDCRFCEYwhIfKj\nrcWOoWRA0dY4GCbAlEQKKmUgFJ1oC0pUWgLDjKGA/BKtA+OPUMCAiKYIJEVRmAjir0QSwBAJIsQY\nklySQBCCzRSSfPvHOZduLrvPbu7u3t2b5/OauXN397vnnGef3c+ec/bsnkcRgZnlZ7dON8DMOsPh\nN8uUw2+WKYffLFMOv1mmHH6zTGUZfkmTJK1p8L5nSfpZP5fT72kHK0kPSvp4efl0SfcNwDLHSwpJ\nQ2vUV0n6YIPzCkmH9rMd/Z62E7oi/Dvz5BhIGi7pq5Kel/SSpIc63aZqIuK2iDiu3v0kzZb0rYFo\n02Ak6aOSVkj6k6RnJP1tK+Zb9Z2y20gaGhFbO92OLjKH4rl7B7AJmNCOhbjfO0/SZOAq4CPAr4DR\nrZp3x9f8km4FxgH/LekVSf9WsRn3MUmrgR9X21Sv3GKQtJukWeU74wuS5knat8E29E63WdITkj70\nxrvounIt+6SkYysKe0u6UVKPpLWSLpM0pLleSbb1L4CTgBkRsTEitkXE0p2YPiR9WtLKcsvhGkm7\nlbWzJP1c0pclbQJml7efXa55XpT0I0kHVcxvctknL0m6HlBFbYfdHkmHS7pf0iZJ6yVdJGkKcBHw\nkfL5/3V535r9KmmIpC+W7V8JnLgTj/8oSb+U9Mdy3tdLelOfu51QrX/q9UWbXAL8e0QsiojtEbE2\nIta2ZM4R0fE/YBXwwYrr44EAbgFGAHsCk4A1taYDZgKLgAOBYcA3gNtrLG+HeQGnAm+jeDP8CPAn\nYHRZOwvYCnwG2L2svwTsW9bvLpc1Atif4t35ExXT/izxuP+Y+JtVY5ozgceBLwPPl5f/YSf6OoAH\ngH0p3nSfAj7e57F+imLLYk9gGvA0xVbGUOBi4Bfl/fcDXgZOKfvmM+X0H+/7+IGRQA/wOWCP8vrR\nZW028K0+7Uz16yeBJ4Gx5eN4oHxcQ+u9voAjgXeXj2U8sAKY2WD/1OyLimkPrdGGryae62U1phkC\nvArMKpe7Brge2LMluet08OuE/+Baga3ypK4Ajq2ojQZeq/aCqDavPvXHgKkVL+B1gCrqvwLOAA4A\n/rfyyQBOAx5oJPz97KuLyr6ZDbwJeD/wCvCOBqcPYErF9X8BFla0d3Wf+98LfKzi+m7A/wAHUbwR\nLaqoqXyBVgv/acCjNdo0m4rwN9CvPwY+WVE7jgbDX6U2E7irwf6p2RcV01YNfz+f67eV81xSvp73\nA34OXN6K+Xd8s7+OZ3fivgcBd5Wbc3+keDPYRvFCSpJ0pqTHKqZ9J0VH91ob5bNR+gPFE3MQxRqv\np2Lab1CsqdplC8Wb2mUR8WpE/IRiTVX3g7UKlf3a+1iq1aB4jF+peHybKEI+ppzu9fuXfVTrORsL\nPNNg++r16w7LLR9DQyT9uaR7JD0n6WXgC+z4XFNl3r39k+qLdthS/r8uInoi4nngS8AJrZh5t4S/\n1k8LK2//EzC890q5//eWivqzwPERsU/F3x5RZ/+o3Ge7ATgX+LOI2AdYTsW+KzBGUuX1cRRbA89S\nrKH2q1jmmyPi8OSj/f9lv5L4u6jGZMsamXcdYysu9z6WXn2fi2cpNrcr+3XPiPgFxWb86/Mq+2gs\n1T0LHFKjVm2ZqX7dYbnlY2jU1yh2GQ6LiDdTbEmpz31q9U+qL5IkfT3xXP+m2jQR8SLFllRbfnrb\nLeFfDxxc5z5PAXtIOlHS7hT7W8Mq6l8HLu/9AEbSWyRNbWDZIyg6d2M53T9RrPkr7Q98WtLukk6l\n2Of7QUT0APcB10p6c/mh4yGS3t/AcomIvRJ/X6gx2UPAauBCSUMlvZdiN+ZHZfvPkrSqzqL/VdIo\nSWOB84DvJu779XJZh5fz37vsA4DvA4dLOlnFMfZPA2+tMZ97gLdKmilpmKSRko4ua+uB8b0frDXQ\nr/Mono8DJY2i2Cdu1EiKzylekfSXwD9XuU+t/kn1RVJEfDLxXKdWFjcDn5K0f/lYZ1L0ZdO6JfxX\nABeXm1PnV7tDRLxEsf/1n8Baii2Byk//vwIsAO6TtJniw7+j+86nynyfAK4FfknxIvxriv2qSouB\nwyg+YLscOCUiXihrZ1Lsez8BvAjcQQsPx1Rp72vAVIpNv5cotlrOjIgny7uMrdL+vuYDSyk+2/g+\ncGNieXdRHGr6TrmZvBw4vqw9T/Fh6ZXACxR9VHXZEbEZmAz8PfAc8DvgA2X5v8r/L0h6pLyc6tcb\nKN7sfg08AtxZ5/FWOh/4R2BzOZ9qb3xV+yfVF210KfAwxcpvBfAoxWuwadpxV9YGOxXfqDsvIlbU\nqAfFJu/TA9sy6zaD4ks+1rho4Bt1ZtA9m/1mNsC82W+WKa/5zTI1oPv85YdNZtZGEdH3ewtVNbXm\nlzRF0m8lPS1pZ461mlmH9Xufv/yG3VMUx27XUByLPK08bl5rGq/5zdpsINb8RwFPR8TKiHgV+A7F\nl0/MbBBoJvxj2PEHEGuo8gMHSTMkLZG0pIllmVmLNfOBX7VNizds1kfEHIozz3iz36yLNLPmX8OO\nv346kB1/HWZmXayZ8D8MHCbp7eVpkD5K8cMaMxsE+r3ZHxFbJZ1L8euqIcBNEVH1d8lm1n0G9Ou9\n3uc3a78B+ZKPmQ1eDr9Zphx+s0w5/GaZcvjNMuXwm2XK5/DbBRx9dO2TFM+fPz857ZFHHpmsr13b\nmmHhrPt4zW+WKYffLFMOv1mmHH6zTDn8Zply+M0y5UN9u4Dx48fXrL322mvJaevVbdflNb9Zphx+\ns0w5/GaZcvjNMuXwm2XK4TfLlMNvlikf59/FrVuXHkdlw4YNA9QS6zZe85tlyuE3y5TDb5Yph98s\nUw6/WaYcfrNMOfxmmfIovYPA3nvvnawvW7asZu25555LTps67bcNTo2O0tvUl3wkrQI2A9uArREx\nsZn5mdnAacU3/D4QEc+3YD5mNoC8z2+WqWbDH8B9kpZKmlHtDpJmSFoiaUmTyzKzFmp2s/+9EbFO\n0v7A/ZKejIiHKu8QEXOAOeAP/My6SVNr/ohYV/7fANwFHNWKRplZ+/U7/JJGSBrZexk4DljeqoaZ\nWXs1s9l/AHCXpN75fDsiftiSVtkOhg8fnqyPHTu2Zu33v/99q5tju4h+hz8iVgLvamFbzGwA+VCf\nWaYcfrNMOfxmmXL4zTLl8JtlyqfuHgQmT57c72mvuuqqFrZkYE2YMCFZHzJkSLK+dOnSVjZnl+M1\nv1mmHH6zTDn8Zply+M0y5fCbZcrhN8uUw2+WKR/nHwTGjBmTrK9atapmbeHChS1uzY5GjBiRrJ9/\n/vk1a+95z3uS0x577LHJ+tatW5P1yy67rGbt6quvTk772muvJeu7Aq/5zTLl8JtlyuE3y5TDb5Yp\nh98sUw6/WaYcfrNMeYjuQWDx4sXJ+rveVfskyqNGjUpOu2XLln61qdcdd9yRrKeO1e+2W3rds3Hj\nxmR9xYoVyXrqPAgPPvhgctopU6Yk692s0SG6veY3y5TDb5Yph98sUw6/WaYcfrNMOfxmmXL4zTLl\n3/MPAvvss0+yfvfdd9esNXsc/5hjjknWTzrppGT91ltvrVn74Q/TI7rPnz8/WX/11VeT9dSYBVOn\nTk1Om4O6a35JN0naIGl5xW37Srpf0u/K/+lvkphZ12lks/+bQN+vO80CFkbEYcDC8rqZDSJ1wx8R\nDwGb+tw8FZhbXp4LTGtxu8yszfq7z39ARPQARESPpP1r3VHSDGBGP5djZm3S9g/8ImIOMAf8wx6z\nbtLfQ33rJY0GKP9vaF2TzGwg9Df8C4Dp5eXpQPqYjJl1nbqb/ZJuByYB+0laA3weuBKYJ+ljwGrg\n1HY2clc3e/bsZP3QQw9N1h999NF+L3vcuHHJ+oUXXpisDx2afgktWrSoZm3Tpr6fI++o3nH8elLH\n+c8+++zktMcff3yyfu+99/arTd2kbvgj4rQapfSICmbW1fz1XrNMOfxmmXL4zTLl8JtlyuE3y5R/\n0tsF9thjj2RdauhMzP1y+umnJ+snnnhisj5v3rxkfeLEiTVrN9xwQ3LaZh144IE1a/WGFp82Lf1z\nlV3hUJ/X/GaZcvjNMuXwm2XK4TfLlMNvlimH3yxTDr9ZpnycvwuccsopTU3/wAMP1KzV+znwrFnN\nnXt1/fr1yfp5553X1PybMWbMmJq1et+tyIHX/GaZcvjNMuXwm2XK4TfLlMNvlimH3yxTDr9Zpnyc\nvwts2JAe82SvvfZK1m+++eaatUmTJiWnHTlyZLJezzXXXNPU9O2UGtp848aNyWmvuOKKVjen63jN\nb5Yph98sUw6/WaYcfrNMOfxmmXL4zTLl8Jtlysf5u8DYsWOT9e3btyfrqaGshw0b1q829UqdKwCg\np6enqfk349RT0yPDX3/99TVr69atS067atWq/jRpUKm75pd0k6QNkpZX3DZb0lpJj5V/J7S3mWbW\nao1s9n8TmFLl9i9HxITy7wetbZaZtVvd8EfEQ8CmAWiLmQ2gZj7wO1fSsnK3YFStO0maIWmJpCVN\nLMvMWqy/4f8acAgwAegBrq11x4iYExETI6L2iI1mNuD6Ff6IWB8R2yJiO3ADcFRrm2Vm7dav8Esa\nXXH1Q8DyWvc1s+5U9zi/pNuBScB+ktYAnwcmSZoABLAK+EQb27jLW7ZsWbJ+xBFH9HveU6ZUO1DT\nuBdffDFZ37ZtW1PzTznjjDOS9XpjAowaVfOjKK677rp+tWlXUjf8EXFalZtvbENbzGwA+eu9Zply\n+M0y5fCbZcrhN8uUw2+WKf+ktwscffTRyXrqJ7vNkpSs1zu19/Dhw5P1gw8+uGbtggsuSE47bdq0\nppa9YMGCmrVLL700OW0OvOY3y5TDb5Yph98sUw6/WaYcfrNMOfxmmXL4zTLl4/xd4M4770zWp0+f\nnqwfc8wxNWsrV65MThsRyfrkyZOT9cWLFyfrhx9+eLKeUu/nxLfcckuyfskll9SstfOnyIOF1/xm\nmXL4zTLl8JtlyuE3y5TDb5Yph98sUw6/WaZU7zhvSxcmDdzCBpF6p6ieO3dusr569eqatTFjxiSn\nHTJkSLLeTvVOWf7www8n61deeWWy/swzz+x0m3YFEZE+SUPJa36zTDn8Zply+M0y5fCbZcrhN8uU\nw2+WKYffLFN1j/NLGgvcArwV2A7MiYivSNoX+C4wnmKY7g9HRPIH2D7OX92wYcOS9dtuuy1ZP/nk\nk2vW6p2Xf/Pmzcl6vfP2f/azn03WH3vssZq1RYsWJafdsmVLsm7VtfI4/1bgcxHxDuDdwDmS/gqY\nBSyMiMOAheV1Mxsk6oY/Inoi4pHy8mZgBTAGmAr0fvVsLpAeXsXMuspO7fNLGg8cASwGDoiIHije\nIID9W904M2ufhs/hJ2kv4HvAzIh4ud6+ZMV0M4AZ/WuembVLQ2t+SbtTBP+2iOg92+R6SaPL+mhg\nQ7VpI2JOREyMiImtaLCZtUbd8KtYxd8IrIiIL1WUFgC9p5WdDsxvffPMrF0aOdT3PuCnwOMUh/oA\nLqLY758HjANWA6dGxKY68/Khvn4YN25csj5v3ryatQ0bqm6Qve7iiy9O1mfOnJmsn3POOcm6D9cN\nvEYP9dXd54+InwG1ZnbszjTKzLqHv+FnlimH3yxTDr9Zphx+s0w5/GaZcvjNMuVTd5vtYnzqbjNL\ncvjNMuXwm2XK4TfLlMNvlimH3yxTDr9Zphx+s0w5/GaZcvjNMuXwm2XK4TfLlMNvlimH3yxTDr9Z\nphx+s0w5/GaZcvjNMuXwm2XK4TfLlMNvlimH3yxTDr9ZpuqGX9JYSQ9IWiHpN5LOK2+fLWmtpMfK\nvxPa31wza5W6g3ZIGg2MjohHJI0ElgLTgA8Dr0TEFxtemAftMGu7RgftGNrAjHqAnvLyZkkrgDHN\nNc/MOm2n9vkljQeOABaXN50raZmkmySNqjHNDElLJC1pqqVm1lINj9UnaS/gJ8DlEXGnpAOA54EA\nLqXYNTi7zjy82W/WZo1u9jcUfkm7A/cAP4qIL1WpjwfuiYh31pmPw2/WZi0bqFOSgBuBFZXBLz8I\n7PUhYPnONtLMOqeRT/vfB/wUeBzYXt58EXAaMIFis38V8Inyw8HUvLzmN2uzlm72t4rDb9Z+Ldvs\nN7Ndk8NvlimH3yxTDr9Zphx+s0w5/GaZcvjNMuXwm2XK4TfLlMNvlimH3yxTDr9Zphx+s0w5/GaZ\nqnsCzxZ7HvhDxfX9ytu6Ube2rVvbBW5bf7WybQc1escB/T3/GxYuLYmIiR1rQEK3tq1b2wVuW391\nqm3e7DfLlMNvlqlOh39Oh5ef0q1t69Z2gdvWXx1pW0f3+c2sczq95jezDnH4zTLVkfBLmiLpt5Ke\nljSrE22oRdIqSY+Xw453dHzBcgzEDZKWV9y2r6T7Jf2u/F91jMQOta0rhm1PDCvf0b7rtuHuB3yf\nX9IQ4ClgMrAGeBg4LSKeGNCG1CBpFTAxIjr+hRBJfwe8AtzSOxSapKuBTRFxZfnGOSoiLuiSts1m\nJ4dtb1Pbag0rfxYd7LtWDnffCp1Y8x8FPB0RKyPiVeA7wNQOtKPrRcRDwKY+N08F5paX51K8eAZc\njbZ1hYjoiYhHysubgd5h5Tvad4l2dUQnwj8GeLbi+ho62AFVBHCfpKWSZnS6MVUc0DssWvl//w63\np6+6w7YPpD7DyndN3/VnuPtW60T4qw0l1E3HG98bEX8DHA+cU27eWmO+BhxCMYZjD3BtJxtTDiv/\nPWBmRLzcybZUqtKujvRbJ8K/Bhhbcf1AYF0H2lFVRKwr/28A7qLYTekm63tHSC7/b+hwe14XEesj\nYltEbAduoIN9Vw4r/z3gtoi4s7y5431XrV2d6rdOhP9h4DBJb5f0JuCjwIIOtOMNJI0oP4hB0gjg\nOLpv6PEFwPTy8nRgfgfbsoNuGba91rDydLjvum24+458w688lPEfwBDgpoi4fMAbUYWkgynW9lD8\n3PnbnWybpNuBSRQ/+VwPfB64G5gHjANWA6dGxIB/8FajbZPYyWHb29S2WsPKL6aDfdfK4e5b0h5/\nvdcsT/6Gn1mmHH6zTDn8Zply+M0y5fCbZcrhN8uUw2+Wqf8DoiHgg922BdkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# select a test image randomly\n",
    "random_test_index = np.random.choice(x_test.shape[0], size=1)[0]\n",
    "test_img = x_test[random_test_index]\n",
    "test_label = np.argmax(y_test[random_test_index])\n",
    "\n",
    "# predict test image with trained model\n",
    "pred_label = model.predict(np.expand_dims(test_img, axis=0))\n",
    "pred_label = np.argmax(pred_label)\n",
    "\n",
    "plt.imshow(test_img, cmap='gray')\n",
    "plt.title('true label = %d, predicted label = %d' % (test_label, pred_label))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn import tree\n",
    "from time import time\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 32.76s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t0 = time()\n",
    "clf_dt = tree.DecisionTreeClassifier()\n",
    "clf_dt.fit(x_train.reshape(-1,28*28), y_train)\n",
    "print('Time elapsed: %.2fs' % (time()-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted 10000 digits with ccuracy: 0.88%\n"
     ]
    }
   ],
   "source": [
    "pred_dt = clf_dt.predict(x_test.reshape(-1,28*28))\n",
    "print('Predicted', len(pred_dt), \"digits with ccuracy: {0:.2f}%\".format(accuracy_score(y_test, pred_dt)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

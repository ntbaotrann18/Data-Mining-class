{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1 Tran Dinh Son\n",
    "#trandinhson3086@gmail.com\n",
    "#Chonnam National University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dense, Dropout\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples :  60000\n",
      "Number of testing samples: 10000\n"
     ]
    }
   ],
   "source": [
    "#the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 28, 28)\n",
    "x_test = x_test.reshape(10000, 28, 28)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print('Number of training samples : ', x_train.shape[0])\n",
    "print('Number of testing samples:', x_test.shape[0])\n",
    "\n",
    "# 10 class from 0 to 9: 0 1 2 3.. 9\n",
    "num_classes = 10\n",
    "#convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           (None, 28, 28)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout1 (Dropout)           (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout2 (Dropout)           (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout3 (Dropout)           (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc4_10ways_softmax (Dense)   (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 932,362\n",
      "Trainable params: 932,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 28x28 MNIST image\n",
    "input_image = Input(shape=(28, 28), name='Input')\n",
    "\n",
    "# matrix ---> vector\n",
    "x = Flatten(name='flatten')(input_image)\n",
    "\n",
    "# FC layers + dropout\n",
    "x = Dense(units=512, activation='relu', name='fc1')(x)\n",
    "x = Dropout(rate=0.2, name='dropout1')(x)\n",
    "\n",
    "x = Dense(units=512, activation='relu', name='fc2')(x)\n",
    "x = Dropout(rate=0.2, name='dropout2')(x)\n",
    "\n",
    "x = Dense(units=512, activation='relu', name='fc3')(x)\n",
    "x = Dropout(rate=0.2, name='dropout3')(x)\n",
    "\n",
    "output_label = Dense(units=num_classes, activation='softmax', name='fc4_10ways_softmax')(x)\n",
    "\n",
    "# define model\n",
    "model = Model(inputs=input_image, outputs=output_label, name='mnist_mlp')\n",
    "\n",
    "# print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 5s - loss: 1.4192 - acc: 0.5988 - val_loss: 0.5544 - val_acc: 0.8639\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.5697 - acc: 0.8324 - val_loss: 0.3580 - val_acc: 0.9010\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.4324 - acc: 0.8716 - val_loss: 0.3018 - val_acc: 0.9122\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.3705 - acc: 0.8914 - val_loss: 0.2691 - val_acc: 0.9214\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.3342 - acc: 0.9015 - val_loss: 0.2457 - val_acc: 0.9289\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.3060 - acc: 0.9107 - val_loss: 0.2283 - val_acc: 0.9319\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.2845 - acc: 0.9158 - val_loss: 0.2130 - val_acc: 0.9361\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.2611 - acc: 0.9242 - val_loss: 0.1987 - val_acc: 0.9392\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.2463 - acc: 0.9278 - val_loss: 0.1867 - val_acc: 0.9431\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.2336 - acc: 0.9308 - val_loss: 0.1767 - val_acc: 0.9470\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.2206 - acc: 0.9349 - val_loss: 0.1672 - val_acc: 0.9496\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.2066 - acc: 0.9389 - val_loss: 0.1595 - val_acc: 0.9505\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.1983 - acc: 0.9412 - val_loss: 0.1518 - val_acc: 0.9522\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.1911 - acc: 0.9432 - val_loss: 0.1456 - val_acc: 0.9540\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.1822 - acc: 0.9466 - val_loss: 0.1402 - val_acc: 0.9549\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.1726 - acc: 0.9491 - val_loss: 0.1359 - val_acc: 0.9567\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.1663 - acc: 0.9511 - val_loss: 0.1312 - val_acc: 0.9576\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.1603 - acc: 0.9530 - val_loss: 0.1262 - val_acc: 0.9597\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.1571 - acc: 0.9534 - val_loss: 0.1214 - val_acc: 0.9599\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.1483 - acc: 0.9569 - val_loss: 0.1182 - val_acc: 0.9617\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.1453 - acc: 0.9570 - val_loss: 0.1149 - val_acc: 0.9633\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.1403 - acc: 0.9583 - val_loss: 0.1116 - val_acc: 0.9641\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.1367 - acc: 0.9584 - val_loss: 0.1094 - val_acc: 0.9647\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.1307 - acc: 0.9610 - val_loss: 0.1058 - val_acc: 0.9662\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.1273 - acc: 0.9620 - val_loss: 0.1037 - val_acc: 0.9659\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.1248 - acc: 0.9627 - val_loss: 0.1015 - val_acc: 0.9667\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.1205 - acc: 0.9642 - val_loss: 0.0990 - val_acc: 0.9683\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.1161 - acc: 0.9654 - val_loss: 0.0979 - val_acc: 0.9686\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.1147 - acc: 0.9651 - val_loss: 0.0953 - val_acc: 0.9699\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 2s - loss: 0.1103 - acc: 0.9670 - val_loss: 0.0941 - val_acc: 0.9698\n",
      "> training time is 1.2873 minutes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# declare learning rate, loss function, and model metric\n",
    "loss = 'categorical_crossentropy'\n",
    "lr = 0.01\n",
    "model.compile(loss=loss, optimizer=SGD(lr=lr), metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "batch_size = 128\n",
    "epochs = 30\n",
    "\n",
    "starting_time = time.time()\n",
    "history = model.fit(x_train, y_train,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs)\n",
    "print('> training time is %.4f minutes' % ((time.time() - starting_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9440/10000 [===========================>..] - ETA: 0sTest loss: 0.0941024177506\n",
      "Test accuracy: 0.9698\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x221550a4278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# select a test image randomly\n",
    "random_test_index = np.random.choice(x_test.shape[0], size=1)[0]\n",
    "test_img = x_test[random_test_index]\n",
    "test_label = np.argmax(y_test[random_test_index])\n",
    "\n",
    "# predict test image with trained model\n",
    "pred_label = model.predict(np.expand_dims(test_img, axis=0))\n",
    "pred_label = np.argmax(pred_label)\n",
    "\n",
    "plt.imshow(test_img, cmap='gray')\n",
    "plt.title('true label = %d, predicted label = %d' % (test_label, pred_label))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
